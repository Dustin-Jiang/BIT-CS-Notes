为了解决 [[处理器]] 与 [[主存储器]] 之间的速度不匹配问题，引入了高速缓冲存储器 (Cache)。

## 引入背景 #重点 

- **矛盾**：现代计算机存在“高速 CPU 与低速主存”之间的速度鸿沟。
- **依据**：Cache 的有效性基于 [[程序局部性原理]]。

## 物理特性

- **材质工艺**：通常采用与 CPU 内部寄存器相同的 SRAM 工艺，访问速度极快。
- **物理位置**：由于工艺一致，通常被封装在处理器芯片内部。
## Cache 的分级体系

现代处理器通常采用三级 Cache 结构以平衡速度与成本：

- **L1 Cache (一级)**: 访问速度最快，容量最小。通常采用**哈佛结构**（指令 Cache 与数据 Cache 分离），允许 CPU 同时读取指令和数据以提升性能。
- **L2 Cache (二级)**: 速度略慢，容量稍大。
- **L3 Cache (三级)**: 通常为多核心共享，容量最大。

## 访存逻辑

CPU 发出主存地址，同时查找 Cache。

- **命中 (Hit)**: 直接访问 Cache。由于局部性原理，命中率通常非常高。
- **不命中 (Miss)**: 访问主存，并将数据所在块调入 Cache。

- **性能评估** ![[Cache性能分析]]
- **映射方式** ![[Cache映射方式]]
- **一致性策略**: 
	- **写全法 (Write-through)**: 同时写入 Cache 和主存。
	- **写回法 (Write-back)**: 只写 Cache，仅在块被替换时才写回主存。 #重点

![[Cache映射方式]]
